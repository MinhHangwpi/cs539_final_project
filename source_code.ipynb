{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:01:31.322074Z","iopub.status.busy":"2023-07-22T15:01:31.321080Z","iopub.status.idle":"2023-07-22T15:01:47.419186Z","shell.execute_reply":"2023-07-22T15:01:47.418145Z","shell.execute_reply.started":"2023-07-22T15:01:31.322032Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (23.1.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (23.3.3)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mediapipe) (3.6.3)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mediapipe) (1.23.5)\n","Requirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.10/site-packages (from mediapipe) (4.7.0.72)\n","Requirement already satisfied: protobuf<4,>=3.11 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (3.20.3)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Requirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (21.3)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.2 sounddevice-0.4.6\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# \n","!pip install mediapipe"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:01:47.421341Z","iopub.status.busy":"2023-07-22T15:01:47.420936Z","iopub.status.idle":"2023-07-22T15:01:59.931512Z","shell.execute_reply":"2023-07-22T15:01:59.930187Z","shell.execute_reply.started":"2023-07-22T15:01:47.421302Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["import os\n","import shutil\n","import numpy as np\n","import pandas as pd\n","import pyarrow.parquet as pq # to read in parquet files\n","import tensorflow as tf\n","import json\n","import mediapipe\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import random\n","\n","from skimage.transform import resize\n","from mediapipe.framework.formats import landmark_pb2\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.losses import BinaryCrossentropy\n","from tqdm.notebook import tqdm\n","from matplotlib import animation, rc"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:01:59.933417Z","iopub.status.busy":"2023-07-22T15:01:59.932730Z","iopub.status.idle":"2023-07-22T15:01:59.939547Z","shell.execute_reply":"2023-07-22T15:01:59.937681Z","shell.execute_reply.started":"2023-07-22T15:01:59.933384Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow v2.12.0\n","Mediapipe v0.10.2\n"]}],"source":["print(\"TensorFlow v\" + tf.__version__)\n","print(\"Mediapipe v\" + mediapipe.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:01:59.943977Z","iopub.status.busy":"2023-07-22T15:01:59.943380Z","iopub.status.idle":"2023-07-22T15:02:00.157909Z","shell.execute_reply":"2023-07-22T15:02:00.156615Z","shell.execute_reply.started":"2023-07-22T15:01:59.943902Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Full train dataset shape is (67208, 5)\n","The first few rows of the train.csv frame is: \n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>file_id</th>\n","      <th>sequence_id</th>\n","      <th>participant_id</th>\n","      <th>phrase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816796431</td>\n","      <td>217</td>\n","      <td>3 creekhouse</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816825349</td>\n","      <td>107</td>\n","      <td>scales/kuhaylah</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816909464</td>\n","      <td>1</td>\n","      <td>1383 william lanier</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1816967051</td>\n","      <td>63</td>\n","      <td>988 franklin lane</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_landmarks/5414471.parquet</td>\n","      <td>5414471</td>\n","      <td>1817123330</td>\n","      <td>89</td>\n","      <td>6920 northeast 661st road</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              path  file_id  sequence_id  participant_id  \\\n","0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n","1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n","2  train_landmarks/5414471.parquet  5414471   1816909464               1   \n","3  train_landmarks/5414471.parquet  5414471   1816967051              63   \n","4  train_landmarks/5414471.parquet  5414471   1817123330              89   \n","\n","                      phrase  \n","0               3 creekhouse  \n","1            scales/kuhaylah  \n","2        1383 william lanier  \n","3          988 franklin lane  \n","4  6920 northeast 661st road  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# the processing code is from https://www.kaggle.com/code/gusthema/asl-fingerspelling-recognition-w-tensorflow\n","\n","# Load the data set\n","\n","dataset_df = pd.read_csv('/kaggle/input/asl-fingerspelling/train.csv')\n","print(\"Full train dataset shape is {}\".format(dataset_df.shape))\n","\n","print(\"The first few rows of the train.csv frame is: \")\n","dataset_df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:00.159431Z","iopub.status.busy":"2023-07-22T15:02:00.159057Z","iopub.status.idle":"2023-07-22T15:02:04.107299Z","shell.execute_reply":"2023-07-22T15:02:04.101962Z","shell.execute_reply.started":"2023-07-22T15:02:00.159399Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The full sequence data frame is:              frame  x_face_0  x_face_1  x_face_2  x_face_3  x_face_4  \\\n","sequence_id                                                            \n","1816796431       0  0.710588  0.699951  0.705657  0.691768  0.699669   \n","1816796431       1  0.709525  0.697582  0.703713  0.691016  0.697576   \n","1816796431       2  0.711059  0.700858  0.706272  0.693285  0.700825   \n","1816796431       3  0.712799  0.702518  0.707840  0.694899  0.702445   \n","1816796431       4  0.712349  0.705451  0.709918  0.696006  0.705180   \n","...            ...       ...       ...       ...       ...       ...   \n","1816796431     118  0.700922  0.689774  0.695984  0.679756  0.688836   \n","1816796431     119  0.700576  0.692017  0.697875  0.682405  0.691249   \n","1816796431     120  0.700621  0.690338  0.696792  0.680982  0.689429   \n","1816796431     121  0.698651  0.693153  0.699358  0.683020  0.692136   \n","1816796431     122  0.698450  0.691408  0.697766  0.681728  0.690405   \n","\n","             x_face_5  x_face_6  x_face_7  x_face_8  ...  z_right_hand_11  \\\n","sequence_id                                          ...                    \n","1816796431   0.701980  0.709724  0.610405  0.712660  ...        -0.245855   \n","1816796431   0.700467  0.709796  0.616540  0.713729  ...              NaN   \n","1816796431   0.703319  0.711549  0.615606  0.715143  ...              NaN   \n","1816796431   0.704794  0.712483  0.625044  0.715677  ...        -0.370770   \n","1816796431   0.706928  0.712685  0.614356  0.714875  ...              NaN   \n","...               ...       ...       ...       ...  ...              ...   \n","1816796431   0.690414  0.696533  0.596424  0.697664  ...              NaN   \n","1816796431   0.692938  0.699178  0.598221  0.700476  ...              NaN   \n","1816796431   0.691177  0.697816  0.599110  0.699297  ...              NaN   \n","1816796431   0.693553  0.699259  0.599576  0.700144  ...              NaN   \n","1816796431   0.691932  0.697955  0.601320  0.698955  ...        -0.562035   \n","\n","             z_right_hand_12  z_right_hand_13  z_right_hand_14  \\\n","sequence_id                                                      \n","1816796431         -0.269148        -0.129743        -0.251501   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431         -0.408097        -0.185217        -0.325494   \n","1816796431               NaN              NaN              NaN   \n","...                      ...              ...              ...   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431         -0.660525        -0.267866        -0.402139   \n","\n","             z_right_hand_15  z_right_hand_16  z_right_hand_17  \\\n","sequence_id                                                      \n","1816796431         -0.278687        -0.266530        -0.152852   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431         -0.343373        -0.328294        -0.203126   \n","1816796431               NaN              NaN              NaN   \n","...                      ...              ...              ...   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431               NaN              NaN              NaN   \n","1816796431         -0.499361        -0.567256        -0.253603   \n","\n","             z_right_hand_18  z_right_hand_19  z_right_hand_20  \n","sequence_id                                                     \n","1816796431         -0.257519        -0.275822        -0.266876  \n","1816796431               NaN              NaN              NaN  \n","1816796431               NaN              NaN              NaN  \n","1816796431         -0.315719        -0.326104        -0.314282  \n","1816796431               NaN              NaN              NaN  \n","...                      ...              ...              ...  \n","1816796431               NaN              NaN              NaN  \n","1816796431               NaN              NaN              NaN  \n","1816796431               NaN              NaN              NaN  \n","1816796431               NaN              NaN              NaN  \n","1816796431         -0.361950        -0.422115        -0.468271  \n","\n","[123 rows x 1630 columns]\n"]}],"source":["# The train.csv looks like a map to point to 67208 parquet files, each contains more detailed coordinate data for each phrase.\n","\n","# fetch the data from a the first parquet file, represents the phrase \"3 creekhouse\".\n","\n","sequence_id, file_id, phrase = dataset_df.iloc[0][['sequence_id', 'file_id', 'phrase']]\n","sample_sequence_df = pq.read_table(f\"/kaggle/input/asl-fingerspelling/train_landmarks/{str(file_id)}.parquet\",\n","                                  filters=[[('sequence_id', '=', sequence_id)], ]).to_pandas() # filter only applied to\n","\n","print(\"The full sequence data frame is:\", sample_sequence_df, end=\"\\n\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:04.109520Z","iopub.status.busy":"2023-07-22T15:02:04.109044Z","iopub.status.idle":"2023-07-22T15:02:04.119587Z","shell.execute_reply":"2023-07-22T15:02:04.118099Z","shell.execute_reply.started":"2023-07-22T15:02:04.109478Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['frame', 'x_face_0', 'x_face_1', 'x_face_2', 'x_face_3', 'x_face_4', 'x_face_5', 'x_face_6', 'x_face_7', 'x_face_8', 'x_face_9', 'x_face_10', 'x_face_11', 'x_face_12', 'x_face_13', 'x_face_14', 'x_face_15', 'x_face_16', 'x_face_17', 'x_face_18', 'x_face_19', 'x_face_20', 'x_face_21', 'x_face_22', 'x_face_23', 'x_face_24', 'x_face_25', 'x_face_26', 'x_face_27', 'x_face_28', 'x_face_29', 'x_face_30', 'x_face_31', 'x_face_32', 'x_face_33', 'x_face_34', 'x_face_35', 'x_face_36', 'x_face_37', 'x_face_38', 'x_face_39', 'x_face_40', 'x_face_41', 'x_face_42', 'x_face_43', 'x_face_44', 'x_face_45', 'x_face_46', 'x_face_47', 'x_face_48', 'x_face_49', 'x_face_50', 'x_face_51', 'x_face_52', 'x_face_53', 'x_face_54', 'x_face_55', 'x_face_56', 'x_face_57', 'x_face_58', 'x_face_59', 'x_face_60', 'x_face_61', 'x_face_62', 'x_face_63', 'x_face_64', 'x_face_65', 'x_face_66', 'x_face_67', 'x_face_68', 'x_face_69', 'x_face_70', 'x_face_71', 'x_face_72', 'x_face_73', 'x_face_74', 'x_face_75', 'x_face_76', 'x_face_77', 'x_face_78', 'x_face_79', 'x_face_80', 'x_face_81', 'x_face_82', 'x_face_83', 'x_face_84', 'x_face_85', 'x_face_86', 'x_face_87', 'x_face_88', 'x_face_89', 'x_face_90', 'x_face_91', 'x_face_92', 'x_face_93', 'x_face_94', 'x_face_95', 'x_face_96', 'x_face_97', 'x_face_98', 'x_face_99', 'x_face_100', 'x_face_101', 'x_face_102', 'x_face_103', 'x_face_104', 'x_face_105', 'x_face_106', 'x_face_107', 'x_face_108', 'x_face_109', 'x_face_110', 'x_face_111', 'x_face_112', 'x_face_113', 'x_face_114', 'x_face_115', 'x_face_116', 'x_face_117', 'x_face_118', 'x_face_119', 'x_face_120', 'x_face_121', 'x_face_122', 'x_face_123', 'x_face_124', 'x_face_125', 'x_face_126', 'x_face_127', 'x_face_128', 'x_face_129', 'x_face_130', 'x_face_131', 'x_face_132', 'x_face_133', 'x_face_134', 'x_face_135', 'x_face_136', 'x_face_137', 'x_face_138', 'x_face_139', 'x_face_140', 'x_face_141', 'x_face_142', 'x_face_143', 'x_face_144', 'x_face_145', 'x_face_146', 'x_face_147', 'x_face_148', 'x_face_149', 'x_face_150', 'x_face_151', 'x_face_152', 'x_face_153', 'x_face_154', 'x_face_155', 'x_face_156', 'x_face_157', 'x_face_158', 'x_face_159', 'x_face_160', 'x_face_161', 'x_face_162', 'x_face_163', 'x_face_164', 'x_face_165', 'x_face_166', 'x_face_167', 'x_face_168', 'x_face_169', 'x_face_170', 'x_face_171', 'x_face_172', 'x_face_173', 'x_face_174', 'x_face_175', 'x_face_176', 'x_face_177', 'x_face_178', 'x_face_179', 'x_face_180', 'x_face_181', 'x_face_182', 'x_face_183', 'x_face_184', 'x_face_185', 'x_face_186', 'x_face_187', 'x_face_188', 'x_face_189', 'x_face_190', 'x_face_191', 'x_face_192', 'x_face_193', 'x_face_194', 'x_face_195', 'x_face_196', 'x_face_197', 'x_face_198', 'x_face_199', 'x_face_200', 'x_face_201', 'x_face_202', 'x_face_203', 'x_face_204', 'x_face_205', 'x_face_206', 'x_face_207', 'x_face_208', 'x_face_209', 'x_face_210', 'x_face_211', 'x_face_212', 'x_face_213', 'x_face_214', 'x_face_215', 'x_face_216', 'x_face_217', 'x_face_218', 'x_face_219', 'x_face_220', 'x_face_221', 'x_face_222', 'x_face_223', 'x_face_224', 'x_face_225', 'x_face_226', 'x_face_227', 'x_face_228', 'x_face_229', 'x_face_230', 'x_face_231', 'x_face_232', 'x_face_233', 'x_face_234', 'x_face_235', 'x_face_236', 'x_face_237', 'x_face_238', 'x_face_239', 'x_face_240', 'x_face_241', 'x_face_242', 'x_face_243', 'x_face_244', 'x_face_245', 'x_face_246', 'x_face_247', 'x_face_248', 'x_face_249', 'x_face_250', 'x_face_251', 'x_face_252', 'x_face_253', 'x_face_254', 'x_face_255', 'x_face_256', 'x_face_257', 'x_face_258', 'x_face_259', 'x_face_260', 'x_face_261', 'x_face_262', 'x_face_263', 'x_face_264', 'x_face_265', 'x_face_266', 'x_face_267', 'x_face_268', 'x_face_269', 'x_face_270', 'x_face_271', 'x_face_272', 'x_face_273', 'x_face_274', 'x_face_275', 'x_face_276', 'x_face_277', 'x_face_278', 'x_face_279', 'x_face_280', 'x_face_281', 'x_face_282', 'x_face_283', 'x_face_284', 'x_face_285', 'x_face_286', 'x_face_287', 'x_face_288', 'x_face_289', 'x_face_290', 'x_face_291', 'x_face_292', 'x_face_293', 'x_face_294', 'x_face_295', 'x_face_296', 'x_face_297', 'x_face_298', 'x_face_299', 'x_face_300', 'x_face_301', 'x_face_302', 'x_face_303', 'x_face_304', 'x_face_305', 'x_face_306', 'x_face_307', 'x_face_308', 'x_face_309', 'x_face_310', 'x_face_311', 'x_face_312', 'x_face_313', 'x_face_314', 'x_face_315', 'x_face_316', 'x_face_317', 'x_face_318', 'x_face_319', 'x_face_320', 'x_face_321', 'x_face_322', 'x_face_323', 'x_face_324', 'x_face_325', 'x_face_326', 'x_face_327', 'x_face_328', 'x_face_329', 'x_face_330', 'x_face_331', 'x_face_332', 'x_face_333', 'x_face_334', 'x_face_335', 'x_face_336', 'x_face_337', 'x_face_338', 'x_face_339', 'x_face_340', 'x_face_341', 'x_face_342', 'x_face_343', 'x_face_344', 'x_face_345', 'x_face_346', 'x_face_347', 'x_face_348', 'x_face_349', 'x_face_350', 'x_face_351', 'x_face_352', 'x_face_353', 'x_face_354', 'x_face_355', 'x_face_356', 'x_face_357', 'x_face_358', 'x_face_359', 'x_face_360', 'x_face_361', 'x_face_362', 'x_face_363', 'x_face_364', 'x_face_365', 'x_face_366', 'x_face_367', 'x_face_368', 'x_face_369', 'x_face_370', 'x_face_371', 'x_face_372', 'x_face_373', 'x_face_374', 'x_face_375', 'x_face_376', 'x_face_377', 'x_face_378', 'x_face_379', 'x_face_380', 'x_face_381', 'x_face_382', 'x_face_383', 'x_face_384', 'x_face_385', 'x_face_386', 'x_face_387', 'x_face_388', 'x_face_389', 'x_face_390', 'x_face_391', 'x_face_392', 'x_face_393', 'x_face_394', 'x_face_395', 'x_face_396', 'x_face_397', 'x_face_398', 'x_face_399', 'x_face_400', 'x_face_401', 'x_face_402', 'x_face_403', 'x_face_404', 'x_face_405', 'x_face_406', 'x_face_407', 'x_face_408', 'x_face_409', 'x_face_410', 'x_face_411', 'x_face_412', 'x_face_413', 'x_face_414', 'x_face_415', 'x_face_416', 'x_face_417', 'x_face_418', 'x_face_419', 'x_face_420', 'x_face_421', 'x_face_422', 'x_face_423', 'x_face_424', 'x_face_425', 'x_face_426', 'x_face_427', 'x_face_428', 'x_face_429', 'x_face_430', 'x_face_431', 'x_face_432', 'x_face_433', 'x_face_434', 'x_face_435', 'x_face_436', 'x_face_437', 'x_face_438', 'x_face_439', 'x_face_440', 'x_face_441', 'x_face_442', 'x_face_443', 'x_face_444', 'x_face_445', 'x_face_446', 'x_face_447', 'x_face_448', 'x_face_449', 'x_face_450', 'x_face_451', 'x_face_452', 'x_face_453', 'x_face_454', 'x_face_455', 'x_face_456', 'x_face_457', 'x_face_458', 'x_face_459', 'x_face_460', 'x_face_461', 'x_face_462', 'x_face_463', 'x_face_464', 'x_face_465', 'x_face_466', 'x_face_467', 'x_left_hand_0', 'x_left_hand_1', 'x_left_hand_2', 'x_left_hand_3', 'x_left_hand_4', 'x_left_hand_5', 'x_left_hand_6', 'x_left_hand_7', 'x_left_hand_8', 'x_left_hand_9', 'x_left_hand_10', 'x_left_hand_11', 'x_left_hand_12', 'x_left_hand_13', 'x_left_hand_14', 'x_left_hand_15', 'x_left_hand_16', 'x_left_hand_17', 'x_left_hand_18', 'x_left_hand_19', 'x_left_hand_20', 'x_pose_0', 'x_pose_1', 'x_pose_2', 'x_pose_3', 'x_pose_4', 'x_pose_5', 'x_pose_6', 'x_pose_7', 'x_pose_8', 'x_pose_9', 'x_pose_10', 'x_pose_11', 'x_pose_12', 'x_pose_13', 'x_pose_14', 'x_pose_15', 'x_pose_16', 'x_pose_17', 'x_pose_18', 'x_pose_19', 'x_pose_20', 'x_pose_21', 'x_pose_22', 'x_pose_23', 'x_pose_24', 'x_pose_25', 'x_pose_26', 'x_pose_27', 'x_pose_28', 'x_pose_29', 'x_pose_30', 'x_pose_31', 'x_pose_32', 'x_right_hand_0', 'x_right_hand_1', 'x_right_hand_2', 'x_right_hand_3', 'x_right_hand_4', 'x_right_hand_5', 'x_right_hand_6', 'x_right_hand_7', 'x_right_hand_8', 'x_right_hand_9', 'x_right_hand_10', 'x_right_hand_11', 'x_right_hand_12', 'x_right_hand_13', 'x_right_hand_14', 'x_right_hand_15', 'x_right_hand_16', 'x_right_hand_17', 'x_right_hand_18', 'x_right_hand_19', 'x_right_hand_20', 'y_face_0', 'y_face_1', 'y_face_2', 'y_face_3', 'y_face_4', 'y_face_5', 'y_face_6', 'y_face_7', 'y_face_8', 'y_face_9', 'y_face_10', 'y_face_11', 'y_face_12', 'y_face_13', 'y_face_14', 'y_face_15', 'y_face_16', 'y_face_17', 'y_face_18', 'y_face_19', 'y_face_20', 'y_face_21', 'y_face_22', 'y_face_23', 'y_face_24', 'y_face_25', 'y_face_26', 'y_face_27', 'y_face_28', 'y_face_29', 'y_face_30', 'y_face_31', 'y_face_32', 'y_face_33', 'y_face_34', 'y_face_35', 'y_face_36', 'y_face_37', 'y_face_38', 'y_face_39', 'y_face_40', 'y_face_41', 'y_face_42', 'y_face_43', 'y_face_44', 'y_face_45', 'y_face_46', 'y_face_47', 'y_face_48', 'y_face_49', 'y_face_50', 'y_face_51', 'y_face_52', 'y_face_53', 'y_face_54', 'y_face_55', 'y_face_56', 'y_face_57', 'y_face_58', 'y_face_59', 'y_face_60', 'y_face_61', 'y_face_62', 'y_face_63', 'y_face_64', 'y_face_65', 'y_face_66', 'y_face_67', 'y_face_68', 'y_face_69', 'y_face_70', 'y_face_71', 'y_face_72', 'y_face_73', 'y_face_74', 'y_face_75', 'y_face_76', 'y_face_77', 'y_face_78', 'y_face_79', 'y_face_80', 'y_face_81', 'y_face_82', 'y_face_83', 'y_face_84', 'y_face_85', 'y_face_86', 'y_face_87', 'y_face_88', 'y_face_89', 'y_face_90', 'y_face_91', 'y_face_92', 'y_face_93', 'y_face_94', 'y_face_95', 'y_face_96', 'y_face_97', 'y_face_98', 'y_face_99', 'y_face_100', 'y_face_101', 'y_face_102', 'y_face_103', 'y_face_104', 'y_face_105', 'y_face_106', 'y_face_107', 'y_face_108', 'y_face_109', 'y_face_110', 'y_face_111', 'y_face_112', 'y_face_113', 'y_face_114', 'y_face_115', 'y_face_116', 'y_face_117', 'y_face_118', 'y_face_119', 'y_face_120', 'y_face_121', 'y_face_122', 'y_face_123', 'y_face_124', 'y_face_125', 'y_face_126', 'y_face_127', 'y_face_128', 'y_face_129', 'y_face_130', 'y_face_131', 'y_face_132', 'y_face_133', 'y_face_134', 'y_face_135', 'y_face_136', 'y_face_137', 'y_face_138', 'y_face_139', 'y_face_140', 'y_face_141', 'y_face_142', 'y_face_143', 'y_face_144', 'y_face_145', 'y_face_146', 'y_face_147', 'y_face_148', 'y_face_149', 'y_face_150', 'y_face_151', 'y_face_152', 'y_face_153', 'y_face_154', 'y_face_155', 'y_face_156', 'y_face_157', 'y_face_158', 'y_face_159', 'y_face_160', 'y_face_161', 'y_face_162', 'y_face_163', 'y_face_164', 'y_face_165', 'y_face_166', 'y_face_167', 'y_face_168', 'y_face_169', 'y_face_170', 'y_face_171', 'y_face_172', 'y_face_173', 'y_face_174', 'y_face_175', 'y_face_176', 'y_face_177', 'y_face_178', 'y_face_179', 'y_face_180', 'y_face_181', 'y_face_182', 'y_face_183', 'y_face_184', 'y_face_185', 'y_face_186', 'y_face_187', 'y_face_188', 'y_face_189', 'y_face_190', 'y_face_191', 'y_face_192', 'y_face_193', 'y_face_194', 'y_face_195', 'y_face_196', 'y_face_197', 'y_face_198', 'y_face_199', 'y_face_200', 'y_face_201', 'y_face_202', 'y_face_203', 'y_face_204', 'y_face_205', 'y_face_206', 'y_face_207', 'y_face_208', 'y_face_209', 'y_face_210', 'y_face_211', 'y_face_212', 'y_face_213', 'y_face_214', 'y_face_215', 'y_face_216', 'y_face_217', 'y_face_218', 'y_face_219', 'y_face_220', 'y_face_221', 'y_face_222', 'y_face_223', 'y_face_224', 'y_face_225', 'y_face_226', 'y_face_227', 'y_face_228', 'y_face_229', 'y_face_230', 'y_face_231', 'y_face_232', 'y_face_233', 'y_face_234', 'y_face_235', 'y_face_236', 'y_face_237', 'y_face_238', 'y_face_239', 'y_face_240', 'y_face_241', 'y_face_242', 'y_face_243', 'y_face_244', 'y_face_245', 'y_face_246', 'y_face_247', 'y_face_248', 'y_face_249', 'y_face_250', 'y_face_251', 'y_face_252', 'y_face_253', 'y_face_254', 'y_face_255', 'y_face_256', 'y_face_257', 'y_face_258', 'y_face_259', 'y_face_260', 'y_face_261', 'y_face_262', 'y_face_263', 'y_face_264', 'y_face_265', 'y_face_266', 'y_face_267', 'y_face_268', 'y_face_269', 'y_face_270', 'y_face_271', 'y_face_272', 'y_face_273', 'y_face_274', 'y_face_275', 'y_face_276', 'y_face_277', 'y_face_278', 'y_face_279', 'y_face_280', 'y_face_281', 'y_face_282', 'y_face_283', 'y_face_284', 'y_face_285', 'y_face_286', 'y_face_287', 'y_face_288', 'y_face_289', 'y_face_290', 'y_face_291', 'y_face_292', 'y_face_293', 'y_face_294', 'y_face_295', 'y_face_296', 'y_face_297', 'y_face_298', 'y_face_299', 'y_face_300', 'y_face_301', 'y_face_302', 'y_face_303', 'y_face_304', 'y_face_305', 'y_face_306', 'y_face_307', 'y_face_308', 'y_face_309', 'y_face_310', 'y_face_311', 'y_face_312', 'y_face_313', 'y_face_314', 'y_face_315', 'y_face_316', 'y_face_317', 'y_face_318', 'y_face_319', 'y_face_320', 'y_face_321', 'y_face_322', 'y_face_323', 'y_face_324', 'y_face_325', 'y_face_326', 'y_face_327', 'y_face_328', 'y_face_329', 'y_face_330', 'y_face_331', 'y_face_332', 'y_face_333', 'y_face_334', 'y_face_335', 'y_face_336', 'y_face_337', 'y_face_338', 'y_face_339', 'y_face_340', 'y_face_341', 'y_face_342', 'y_face_343', 'y_face_344', 'y_face_345', 'y_face_346', 'y_face_347', 'y_face_348', 'y_face_349', 'y_face_350', 'y_face_351', 'y_face_352', 'y_face_353', 'y_face_354', 'y_face_355', 'y_face_356', 'y_face_357', 'y_face_358', 'y_face_359', 'y_face_360', 'y_face_361', 'y_face_362', 'y_face_363', 'y_face_364', 'y_face_365', 'y_face_366', 'y_face_367', 'y_face_368', 'y_face_369', 'y_face_370', 'y_face_371', 'y_face_372', 'y_face_373', 'y_face_374', 'y_face_375', 'y_face_376', 'y_face_377', 'y_face_378', 'y_face_379', 'y_face_380', 'y_face_381', 'y_face_382', 'y_face_383', 'y_face_384', 'y_face_385', 'y_face_386', 'y_face_387', 'y_face_388', 'y_face_389', 'y_face_390', 'y_face_391', 'y_face_392', 'y_face_393', 'y_face_394', 'y_face_395', 'y_face_396', 'y_face_397', 'y_face_398', 'y_face_399', 'y_face_400', 'y_face_401', 'y_face_402', 'y_face_403', 'y_face_404', 'y_face_405', 'y_face_406', 'y_face_407', 'y_face_408', 'y_face_409', 'y_face_410', 'y_face_411', 'y_face_412', 'y_face_413', 'y_face_414', 'y_face_415', 'y_face_416', 'y_face_417', 'y_face_418', 'y_face_419', 'y_face_420', 'y_face_421', 'y_face_422', 'y_face_423', 'y_face_424', 'y_face_425', 'y_face_426', 'y_face_427', 'y_face_428', 'y_face_429', 'y_face_430', 'y_face_431', 'y_face_432', 'y_face_433', 'y_face_434', 'y_face_435', 'y_face_436', 'y_face_437', 'y_face_438', 'y_face_439', 'y_face_440', 'y_face_441', 'y_face_442', 'y_face_443', 'y_face_444', 'y_face_445', 'y_face_446', 'y_face_447', 'y_face_448', 'y_face_449', 'y_face_450', 'y_face_451', 'y_face_452', 'y_face_453', 'y_face_454', 'y_face_455', 'y_face_456', 'y_face_457', 'y_face_458', 'y_face_459', 'y_face_460', 'y_face_461', 'y_face_462', 'y_face_463', 'y_face_464', 'y_face_465', 'y_face_466', 'y_face_467', 'y_left_hand_0', 'y_left_hand_1', 'y_left_hand_2', 'y_left_hand_3', 'y_left_hand_4', 'y_left_hand_5', 'y_left_hand_6', 'y_left_hand_7', 'y_left_hand_8', 'y_left_hand_9', 'y_left_hand_10', 'y_left_hand_11', 'y_left_hand_12', 'y_left_hand_13', 'y_left_hand_14', 'y_left_hand_15', 'y_left_hand_16', 'y_left_hand_17', 'y_left_hand_18', 'y_left_hand_19', 'y_left_hand_20', 'y_pose_0', 'y_pose_1', 'y_pose_2', 'y_pose_3', 'y_pose_4', 'y_pose_5', 'y_pose_6', 'y_pose_7', 'y_pose_8', 'y_pose_9', 'y_pose_10', 'y_pose_11', 'y_pose_12', 'y_pose_13', 'y_pose_14', 'y_pose_15', 'y_pose_16', 'y_pose_17', 'y_pose_18', 'y_pose_19', 'y_pose_20', 'y_pose_21', 'y_pose_22', 'y_pose_23', 'y_pose_24', 'y_pose_25', 'y_pose_26', 'y_pose_27', 'y_pose_28', 'y_pose_29', 'y_pose_30', 'y_pose_31', 'y_pose_32', 'y_right_hand_0', 'y_right_hand_1', 'y_right_hand_2', 'y_right_hand_3', 'y_right_hand_4', 'y_right_hand_5', 'y_right_hand_6', 'y_right_hand_7', 'y_right_hand_8', 'y_right_hand_9', 'y_right_hand_10', 'y_right_hand_11', 'y_right_hand_12', 'y_right_hand_13', 'y_right_hand_14', 'y_right_hand_15', 'y_right_hand_16', 'y_right_hand_17', 'y_right_hand_18', 'y_right_hand_19', 'y_right_hand_20', 'z_face_0', 'z_face_1', 'z_face_2', 'z_face_3', 'z_face_4', 'z_face_5', 'z_face_6', 'z_face_7', 'z_face_8', 'z_face_9', 'z_face_10', 'z_face_11', 'z_face_12', 'z_face_13', 'z_face_14', 'z_face_15', 'z_face_16', 'z_face_17', 'z_face_18', 'z_face_19', 'z_face_20', 'z_face_21', 'z_face_22', 'z_face_23', 'z_face_24', 'z_face_25', 'z_face_26', 'z_face_27', 'z_face_28', 'z_face_29', 'z_face_30', 'z_face_31', 'z_face_32', 'z_face_33', 'z_face_34', 'z_face_35', 'z_face_36', 'z_face_37', 'z_face_38', 'z_face_39', 'z_face_40', 'z_face_41', 'z_face_42', 'z_face_43', 'z_face_44', 'z_face_45', 'z_face_46', 'z_face_47', 'z_face_48', 'z_face_49', 'z_face_50', 'z_face_51', 'z_face_52', 'z_face_53', 'z_face_54', 'z_face_55', 'z_face_56', 'z_face_57', 'z_face_58', 'z_face_59', 'z_face_60', 'z_face_61', 'z_face_62', 'z_face_63', 'z_face_64', 'z_face_65', 'z_face_66', 'z_face_67', 'z_face_68', 'z_face_69', 'z_face_70', 'z_face_71', 'z_face_72', 'z_face_73', 'z_face_74', 'z_face_75', 'z_face_76', 'z_face_77', 'z_face_78', 'z_face_79', 'z_face_80', 'z_face_81', 'z_face_82', 'z_face_83', 'z_face_84', 'z_face_85', 'z_face_86', 'z_face_87', 'z_face_88', 'z_face_89', 'z_face_90', 'z_face_91', 'z_face_92', 'z_face_93', 'z_face_94', 'z_face_95', 'z_face_96', 'z_face_97', 'z_face_98', 'z_face_99', 'z_face_100', 'z_face_101', 'z_face_102', 'z_face_103', 'z_face_104', 'z_face_105', 'z_face_106', 'z_face_107', 'z_face_108', 'z_face_109', 'z_face_110', 'z_face_111', 'z_face_112', 'z_face_113', 'z_face_114', 'z_face_115', 'z_face_116', 'z_face_117', 'z_face_118', 'z_face_119', 'z_face_120', 'z_face_121', 'z_face_122', 'z_face_123', 'z_face_124', 'z_face_125', 'z_face_126', 'z_face_127', 'z_face_128', 'z_face_129', 'z_face_130', 'z_face_131', 'z_face_132', 'z_face_133', 'z_face_134', 'z_face_135', 'z_face_136', 'z_face_137', 'z_face_138', 'z_face_139', 'z_face_140', 'z_face_141', 'z_face_142', 'z_face_143', 'z_face_144', 'z_face_145', 'z_face_146', 'z_face_147', 'z_face_148', 'z_face_149', 'z_face_150', 'z_face_151', 'z_face_152', 'z_face_153', 'z_face_154', 'z_face_155', 'z_face_156', 'z_face_157', 'z_face_158', 'z_face_159', 'z_face_160', 'z_face_161', 'z_face_162', 'z_face_163', 'z_face_164', 'z_face_165', 'z_face_166', 'z_face_167', 'z_face_168', 'z_face_169', 'z_face_170', 'z_face_171', 'z_face_172', 'z_face_173', 'z_face_174', 'z_face_175', 'z_face_176', 'z_face_177', 'z_face_178', 'z_face_179', 'z_face_180', 'z_face_181', 'z_face_182', 'z_face_183', 'z_face_184', 'z_face_185', 'z_face_186', 'z_face_187', 'z_face_188', 'z_face_189', 'z_face_190', 'z_face_191', 'z_face_192', 'z_face_193', 'z_face_194', 'z_face_195', 'z_face_196', 'z_face_197', 'z_face_198', 'z_face_199', 'z_face_200', 'z_face_201', 'z_face_202', 'z_face_203', 'z_face_204', 'z_face_205', 'z_face_206', 'z_face_207', 'z_face_208', 'z_face_209', 'z_face_210', 'z_face_211', 'z_face_212', 'z_face_213', 'z_face_214', 'z_face_215', 'z_face_216', 'z_face_217', 'z_face_218', 'z_face_219', 'z_face_220', 'z_face_221', 'z_face_222', 'z_face_223', 'z_face_224', 'z_face_225', 'z_face_226', 'z_face_227', 'z_face_228', 'z_face_229', 'z_face_230', 'z_face_231', 'z_face_232', 'z_face_233', 'z_face_234', 'z_face_235', 'z_face_236', 'z_face_237', 'z_face_238', 'z_face_239', 'z_face_240', 'z_face_241', 'z_face_242', 'z_face_243', 'z_face_244', 'z_face_245', 'z_face_246', 'z_face_247', 'z_face_248', 'z_face_249', 'z_face_250', 'z_face_251', 'z_face_252', 'z_face_253', 'z_face_254', 'z_face_255', 'z_face_256', 'z_face_257', 'z_face_258', 'z_face_259', 'z_face_260', 'z_face_261', 'z_face_262', 'z_face_263', 'z_face_264', 'z_face_265', 'z_face_266', 'z_face_267', 'z_face_268', 'z_face_269', 'z_face_270', 'z_face_271', 'z_face_272', 'z_face_273', 'z_face_274', 'z_face_275', 'z_face_276', 'z_face_277', 'z_face_278', 'z_face_279', 'z_face_280', 'z_face_281', 'z_face_282', 'z_face_283', 'z_face_284', 'z_face_285', 'z_face_286', 'z_face_287', 'z_face_288', 'z_face_289', 'z_face_290', 'z_face_291', 'z_face_292', 'z_face_293', 'z_face_294', 'z_face_295', 'z_face_296', 'z_face_297', 'z_face_298', 'z_face_299', 'z_face_300', 'z_face_301', 'z_face_302', 'z_face_303', 'z_face_304', 'z_face_305', 'z_face_306', 'z_face_307', 'z_face_308', 'z_face_309', 'z_face_310', 'z_face_311', 'z_face_312', 'z_face_313', 'z_face_314', 'z_face_315', 'z_face_316', 'z_face_317', 'z_face_318', 'z_face_319', 'z_face_320', 'z_face_321', 'z_face_322', 'z_face_323', 'z_face_324', 'z_face_325', 'z_face_326', 'z_face_327', 'z_face_328', 'z_face_329', 'z_face_330', 'z_face_331', 'z_face_332', 'z_face_333', 'z_face_334', 'z_face_335', 'z_face_336', 'z_face_337', 'z_face_338', 'z_face_339', 'z_face_340', 'z_face_341', 'z_face_342', 'z_face_343', 'z_face_344', 'z_face_345', 'z_face_346', 'z_face_347', 'z_face_348', 'z_face_349', 'z_face_350', 'z_face_351', 'z_face_352', 'z_face_353', 'z_face_354', 'z_face_355', 'z_face_356', 'z_face_357', 'z_face_358', 'z_face_359', 'z_face_360', 'z_face_361', 'z_face_362', 'z_face_363', 'z_face_364', 'z_face_365', 'z_face_366', 'z_face_367', 'z_face_368', 'z_face_369', 'z_face_370', 'z_face_371', 'z_face_372', 'z_face_373', 'z_face_374', 'z_face_375', 'z_face_376', 'z_face_377', 'z_face_378', 'z_face_379', 'z_face_380', 'z_face_381', 'z_face_382', 'z_face_383', 'z_face_384', 'z_face_385', 'z_face_386', 'z_face_387', 'z_face_388', 'z_face_389', 'z_face_390', 'z_face_391', 'z_face_392', 'z_face_393', 'z_face_394', 'z_face_395', 'z_face_396', 'z_face_397', 'z_face_398', 'z_face_399', 'z_face_400', 'z_face_401', 'z_face_402', 'z_face_403', 'z_face_404', 'z_face_405', 'z_face_406', 'z_face_407', 'z_face_408', 'z_face_409', 'z_face_410', 'z_face_411', 'z_face_412', 'z_face_413', 'z_face_414', 'z_face_415', 'z_face_416', 'z_face_417', 'z_face_418', 'z_face_419', 'z_face_420', 'z_face_421', 'z_face_422', 'z_face_423', 'z_face_424', 'z_face_425', 'z_face_426', 'z_face_427', 'z_face_428', 'z_face_429', 'z_face_430', 'z_face_431', 'z_face_432', 'z_face_433', 'z_face_434', 'z_face_435', 'z_face_436', 'z_face_437', 'z_face_438', 'z_face_439', 'z_face_440', 'z_face_441', 'z_face_442', 'z_face_443', 'z_face_444', 'z_face_445', 'z_face_446', 'z_face_447', 'z_face_448', 'z_face_449', 'z_face_450', 'z_face_451', 'z_face_452', 'z_face_453', 'z_face_454', 'z_face_455', 'z_face_456', 'z_face_457', 'z_face_458', 'z_face_459', 'z_face_460', 'z_face_461', 'z_face_462', 'z_face_463', 'z_face_464', 'z_face_465', 'z_face_466', 'z_face_467', 'z_left_hand_0', 'z_left_hand_1', 'z_left_hand_2', 'z_left_hand_3', 'z_left_hand_4', 'z_left_hand_5', 'z_left_hand_6', 'z_left_hand_7', 'z_left_hand_8', 'z_left_hand_9', 'z_left_hand_10', 'z_left_hand_11', 'z_left_hand_12', 'z_left_hand_13', 'z_left_hand_14', 'z_left_hand_15', 'z_left_hand_16', 'z_left_hand_17', 'z_left_hand_18', 'z_left_hand_19', 'z_left_hand_20', 'z_pose_0', 'z_pose_1', 'z_pose_2', 'z_pose_3', 'z_pose_4', 'z_pose_5', 'z_pose_6', 'z_pose_7', 'z_pose_8', 'z_pose_9', 'z_pose_10', 'z_pose_11', 'z_pose_12', 'z_pose_13', 'z_pose_14', 'z_pose_15', 'z_pose_16', 'z_pose_17', 'z_pose_18', 'z_pose_19', 'z_pose_20', 'z_pose_21', 'z_pose_22', 'z_pose_23', 'z_pose_24', 'z_pose_25', 'z_pose_26', 'z_pose_27', 'z_pose_28', 'z_pose_29', 'z_pose_30', 'z_pose_31', 'z_pose_32', 'z_right_hand_0', 'z_right_hand_1', 'z_right_hand_2', 'z_right_hand_3', 'z_right_hand_4', 'z_right_hand_5', 'z_right_hand_6', 'z_right_hand_7', 'z_right_hand_8', 'z_right_hand_9', 'z_right_hand_10', 'z_right_hand_11', 'z_right_hand_12', 'z_right_hand_13', 'z_right_hand_14', 'z_right_hand_15', 'z_right_hand_16', 'z_right_hand_17', 'z_right_hand_18', 'z_right_hand_19', 'z_right_hand_20']\n","the number of columns representing face landmarks:  1404\n","the number of columns representing right_hand landmarks:  63\n","the number of columns representing left_hand landmarks:  63\n","the number of columns representing pose landmarks:  99\n"]}],"source":["\n","# Check what the columns represent\n","# there are 4 landmark types: face, left_hand, right_hand, pose\n","# face seems to have the most columns\n","#\n","print(sample_sequence_df.columns.tolist())  #outputs a list of 1630 columns representing body landmarks + landmark index.\n","print(\"the number of columns representing face landmarks: \", sum(['face' in col for col in sample_sequence_df.columns])) # print: 1404\n","print(\"the number of columns representing right_hand landmarks: \", sum(['right_hand' in col for col in sample_sequence_df.columns])) # print: 63\n","print(\"the number of columns representing left_hand landmarks: \", sum(['left_hand' in col for col in sample_sequence_df.columns])) # print: 63\n","print(\"the number of columns representing pose landmarks: \", sum(['pose' in col for col in sample_sequence_df.columns])) # print: 99\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:04.122035Z","iopub.status.busy":"2023-07-22T15:02:04.121174Z","iopub.status.idle":"2023-07-22T15:02:04.139075Z","shell.execute_reply":"2023-07-22T15:02:04.137718Z","shell.execute_reply.started":"2023-07-22T15:02:04.121989Z"},"trusted":true},"outputs":[],"source":["# for full explanation of what each face landmark index represents: https://developers.google.com/mediapipe/solutions/vision/face_landmarker\n","# for full explanation of what each hand landmark index represents: https://developers.google.com/mediapipe/solutions/vision/hand_landmarker\n","# for full explanation of what each pose landmark index represents: https://developers.google.com/mediapipe/solutions/vision/pose_landmarker"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:04.141667Z","iopub.status.busy":"2023-07-22T15:02:04.140376Z","iopub.status.idle":"2023-07-22T15:02:04.229548Z","shell.execute_reply":"2023-07-22T15:02:04.228477Z","shell.execute_reply.started":"2023-07-22T15:02:04.141523Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["List of 68 TFRecord files\n"]}],"source":["# Get the saved TFRecord files into a list\n","\n","tf_records = dataset_df.file_id.map(lambda x: f'/kaggle/working/preprocessed/{x}.tfrecord').unique()\n","print(f\"List of {len(tf_records)} TFRecord files\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:04.231663Z","iopub.status.busy":"2023-07-22T15:02:04.231185Z","iopub.status.idle":"2023-07-22T15:02:04.240564Z","shell.execute_reply":"2023-07-22T15:02:04.239443Z","shell.execute_reply.started":"2023-07-22T15:02:04.231624Z"},"trusted":true},"outputs":[],"source":["# mediapipe apis allow us to visualize the hand landmarks data\n","\n","# Function create animation from images\n","matplotlib.rcParams['animation.embed_limit'] = 2**128 # maximum size of the animation that can be embedded.\n","matplotlib.rcParams['savefig.pad_inches'] = 0 # set padding between the image and the edge of the saved figure.\n","rc('animation', html='jshtml') # set the format of the animation output to HTML5.\n","\n","def create_animation(images):\n","    fig = plt.figure(figsize=(6,9))\n","    ax = plt.Axes(fig, [0., 0., 1., 1.])\n","    ax.set_axis_off()\n","    fig.add_axes(ax)\n","    im = ax.imshow(images[0], cmap='gray')\n","    plt.close(fig)\n","    \n","    def animate_func(i):\n","        im.set_array(images[i])\n","        return [im]\n","    \n","    return animation.FuncAnimation(fig, animate_func, frames=len(images), interval= 1000/10) # `animation` is a class from the Matplotlib library.\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:04.244926Z","iopub.status.busy":"2023-07-22T15:02:04.244546Z","iopub.status.idle":"2023-07-22T15:02:04.260092Z","shell.execute_reply":"2023-07-22T15:02:04.259004Z","shell.execute_reply.started":"2023-07-22T15:02:04.244889Z"},"trusted":true},"outputs":[],"source":["# Extract the landmark data and convert it to an image using medipipe library.\n","# This function extracts the data for both hands.\n","\n","mp_pose = mediapipe.solutions.pose\n","mp_hands = mediapipe.solutions.hands\n","mp_drawing = mediapipe.solutions.drawing_utils \n","mp_drawing_styles = mediapipe.solutions.drawing_styles\n","\n","def get_hands(seq_df):\n","    images = []\n","    all_hand_landmarks = []\n","    for seq_idx in range(len(seq_df)):\n","        x_hand = seq_df.iloc[seq_idx].filter(regex=\"x_right_hand.*\").values\n","        y_hand = seq_df.iloc[seq_idx].filter(regex=\"y_right_hand.*\").values\n","        z_hand = seq_df.iloc[seq_idx].filter(regex=\"z_right_hand.*\").values\n","\n","        right_hand_image = np.zeros((600, 600, 3))\n","\n","        right_hand_landmarks = landmark_pb2.NormalizedLandmarkList()\n","        \n","        for x, y, z in zip(x_hand, y_hand, z_hand):\n","            right_hand_landmarks.landmark.add(x=x, y=y, z=z)\n","\n","        mp_drawing.draw_landmarks(\n","                right_hand_image,\n","                right_hand_landmarks,\n","                mp_hands.HAND_CONNECTIONS,\n","                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style())\n","        \n","        x_hand = seq_df.iloc[seq_idx].filter(regex=\"x_left_hand.*\").values\n","        y_hand = seq_df.iloc[seq_idx].filter(regex=\"y_left_hand.*\").values\n","        z_hand = seq_df.iloc[seq_idx].filter(regex=\"z_left_hand.*\").values\n","        \n","        left_hand_image = np.zeros((600, 600, 3))\n","        \n","        left_hand_landmarks = landmark_pb2.NormalizedLandmarkList()\n","        for x, y, z in zip(x_hand, y_hand, z_hand):\n","            left_hand_landmarks.landmark.add(x=x, y=y, z=z)\n","\n","        mp_drawing.draw_landmarks(\n","                left_hand_image,\n","                left_hand_landmarks,\n","                mp_hands.HAND_CONNECTIONS,\n","                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style())\n","        \n","        images.append([right_hand_image.astype(np.uint8), left_hand_image.astype(np.uint8)])\n","        all_hand_landmarks.append([right_hand_landmarks, left_hand_landmarks])\n","    return images, all_hand_landmarks"]},{"cell_type":"markdown","metadata":{},"source":["# Visualize the hand landmarks for the first phrase '3 creekhouse'"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:04.261959Z","iopub.status.busy":"2023-07-22T15:02:04.261428Z","iopub.status.idle":"2023-07-22T15:02:15.803360Z","shell.execute_reply":"2023-07-22T15:02:15.801951Z","shell.execute_reply.started":"2023-07-22T15:02:04.261928Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from ffmpeg-python) (0.18.3)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install ffmpeg-python"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:15.805533Z","iopub.status.busy":"2023-07-22T15:02:15.805089Z","iopub.status.idle":"2023-07-22T15:02:18.600187Z","shell.execute_reply":"2023-07-22T15:02:18.599130Z","shell.execute_reply.started":"2023-07-22T15:02:15.805497Z"},"trusted":true},"outputs":[],"source":["# Get the images created using mediapipe apis\n","hand_images, hand_landmarks = get_hands(sample_sequence_df)\n","# Fetch and show the data for right hand\n","anim_0 = create_animation(np.array(hand_images)[:, 0])\n","# saving to m4 using ffmpeg writer"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:18.601788Z","iopub.status.busy":"2023-07-22T15:02:18.601486Z","iopub.status.idle":"2023-07-22T15:02:25.943264Z","shell.execute_reply":"2023-07-22T15:02:25.942295Z","shell.execute_reply.started":"2023-07-22T15:02:18.601764Z"},"trusted":true},"outputs":[],"source":["writervideo = animation.FFMpegWriter(fps=10)\n","anim_0.save('3_creekhouse.mp4', writer=writervideo)"]},{"cell_type":"markdown","metadata":{},"source":["# Visualize the hand landmarks for the second phrase\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:25.944807Z","iopub.status.busy":"2023-07-22T15:02:25.944493Z","iopub.status.idle":"2023-07-22T15:02:30.452789Z","shell.execute_reply":"2023-07-22T15:02:30.451420Z","shell.execute_reply.started":"2023-07-22T15:02:25.944780Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The full sequence data frame is:              frame  x_face_0  x_face_1  x_face_2  x_face_3  x_face_4  \\\n","sequence_id                                                            \n","1816825349       0  0.576603  0.572630  0.571910  0.561432  0.573156   \n","1816825349       1  0.577659  0.572186  0.571878  0.560978  0.572593   \n","1816825349       2  0.578764  0.571128  0.571279  0.560064  0.571451   \n","1816825349       3  0.577037  0.572955  0.572655  0.561425  0.573298   \n","1816825349       4  0.577897  0.573944  0.573857  0.562747  0.574342   \n","...            ...       ...       ...       ...       ...       ...   \n","1816825349     122  0.589847  0.587060  0.585885  0.574620  0.587475   \n","1816825349     123  0.590409  0.586016  0.585070  0.573692  0.586407   \n","1816825349     124  0.589767  0.586228  0.585293  0.574049  0.586645   \n","1816825349     125  0.589624  0.585901  0.585115  0.573770  0.586331   \n","1816825349     126  0.586389  0.586615  0.585369  0.574449  0.587103   \n","\n","             x_face_5  x_face_6  x_face_7  x_face_8  ...  z_right_hand_11  \\\n","sequence_id                                          ...                    \n","1816825349   0.573785  0.575195  0.466567  0.576332  ...        -0.116462   \n","1816825349   0.573172  0.574536  0.467063  0.575519  ...        -0.119139   \n","1816825349   0.572063  0.573591  0.467600  0.574491  ...        -0.107538   \n","1816825349   0.573777  0.574884  0.468297  0.575754  ...        -0.099418   \n","1816825349   0.574992  0.576565  0.469742  0.577687  ...        -0.100494   \n","...               ...       ...       ...       ...  ...              ...   \n","1816825349   0.587659  0.587626  0.479187  0.588135  ...              NaN   \n","1816825349   0.586620  0.586729  0.479678  0.587320  ...        -0.072772   \n","1816825349   0.586892  0.587091  0.479725  0.587598  ...        -0.064531   \n","1816825349   0.586632  0.586997  0.479578  0.587587  ...              NaN   \n","1816825349   0.587382  0.587612  0.479239  0.588170  ...        -0.061375   \n","\n","             z_right_hand_12  z_right_hand_13  z_right_hand_14  \\\n","sequence_id                                                      \n","1816825349         -0.109139        -0.045837        -0.113405   \n","1816825349         -0.112221        -0.053919        -0.118385   \n","1816825349         -0.098405        -0.047151        -0.113827   \n","1816825349         -0.090315        -0.044131        -0.110088   \n","1816825349         -0.088409        -0.041452        -0.110016   \n","...                      ...              ...              ...   \n","1816825349               NaN              NaN              NaN   \n","1816825349         -0.061717        -0.010074        -0.068721   \n","1816825349         -0.053874        -0.005317        -0.062335   \n","1816825349               NaN              NaN              NaN   \n","1816825349         -0.051346        -0.004864        -0.059970   \n","\n","             z_right_hand_15  z_right_hand_16  z_right_hand_17  \\\n","sequence_id                                                      \n","1816825349         -0.097462        -0.066249        -0.061689   \n","1816825349         -0.098422        -0.067452        -0.071212   \n","1816825349         -0.095616        -0.065397        -0.064385   \n","1816825349         -0.095210        -0.068663        -0.060530   \n","1816825349         -0.095791        -0.068828        -0.057276   \n","...                      ...              ...              ...   \n","1816825349               NaN              NaN              NaN   \n","1816825349         -0.060377        -0.034663        -0.019043   \n","1816825349         -0.053141        -0.026223        -0.016631   \n","1816825349               NaN              NaN              NaN   \n","1816825349         -0.050777        -0.024486        -0.015558   \n","\n","             z_right_hand_18  z_right_hand_19  z_right_hand_20  \n","sequence_id                                                     \n","1816825349         -0.105617        -0.087664        -0.060143  \n","1816825349         -0.107935        -0.084754        -0.056558  \n","1816825349         -0.102523        -0.080120        -0.051573  \n","1816825349         -0.096729        -0.077264        -0.051286  \n","1816825349         -0.095703        -0.080402        -0.056874  \n","...                      ...              ...              ...  \n","1816825349               NaN              NaN              NaN  \n","1816825349         -0.058197        -0.049389        -0.028401  \n","1816825349         -0.053787        -0.042219        -0.018836  \n","1816825349               NaN              NaN              NaN  \n","1816825349         -0.053116        -0.041055        -0.016970  \n","\n","[127 rows x 1630 columns]\n","Phrase name:  scales/kuhaylah\n"]}],"source":["\n","sequence_id_2, file_id_2, phrase_2 = dataset_df.iloc[1][['sequence_id', 'file_id', 'phrase']]\n","sample_sequence_df_2 = pq.read_table(f\"/kaggle/input/asl-fingerspelling/train_landmarks/{str(file_id_2)}.parquet\",\n","                                  filters=[[('sequence_id', '=', sequence_id_2)], ]).to_pandas() # filter only applied to\n","print(\"The full sequence data frame is:\", sample_sequence_df_2, end=\"\\n\")\n","print(\"Phrase name: \", phrase_2)\n","\n","# Get the images created using mediapipe apis\n","hand_images_2, hand_landmarks_2 = get_hands(sample_sequence_df_2)\n","# Fetch and show the data for right hand\n","anim_1 = create_animation(np.array(hand_images_2)[:, 0])"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:30.454955Z","iopub.status.busy":"2023-07-22T15:02:30.454311Z","iopub.status.idle":"2023-07-22T15:02:37.481296Z","shell.execute_reply":"2023-07-22T15:02:37.480128Z","shell.execute_reply.started":"2023-07-22T15:02:30.454914Z"},"trusted":true},"outputs":[],"source":["anim_1.save('scaleskuhaylah.mp4', writer=writervideo)"]},{"cell_type":"markdown","metadata":{},"source":["# Visualize the hand landmarks for the third phrase"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:37.483011Z","iopub.status.busy":"2023-07-22T15:02:37.482687Z","iopub.status.idle":"2023-07-22T15:02:44.338325Z","shell.execute_reply":"2023-07-22T15:02:44.336951Z","shell.execute_reply.started":"2023-07-22T15:02:37.482983Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The full sequence data frame is:              frame  x_face_0  x_face_1  x_face_2  x_face_3  x_face_4  \\\n","sequence_id                                                            \n","1816909464       0  0.633601  0.618904  0.623231  0.606461  0.618572   \n","1816909464       1  0.635823  0.636086  0.636008  0.621483  0.636530   \n","1816909464       2  0.637647  0.630321  0.632407  0.615979  0.630152   \n","1816909464       3  0.639373  0.631797  0.633379  0.618251  0.631952   \n","1816909464       4  0.643489  0.633707  0.634779  0.620286  0.633956   \n","...            ...       ...       ...       ...       ...       ...   \n","1816909464     231  0.635170  0.631320  0.632036  0.616967  0.631535   \n","1816909464     232  0.635081  0.629520  0.630180  0.615285  0.629818   \n","1816909464     233  0.634258  0.627670  0.629056  0.614137  0.627872   \n","1816909464     234  0.632718  0.625626  0.627087  0.612802  0.626109   \n","1816909464     235  0.636664  0.631540  0.632232  0.617529  0.631941   \n","\n","             x_face_5  x_face_6  x_face_7  x_face_8  ...  z_right_hand_11  \\\n","sequence_id                                          ...                    \n","1816909464   0.620224  0.626085  0.514628  0.628102  ...        -0.111414   \n","1816909464   0.637268  0.639157  0.515761  0.639826  ...        -0.122258   \n","1816909464   0.631036  0.633997  0.513262  0.634560  ...        -0.086482   \n","1816909464   0.633096  0.636713  0.514751  0.638028  ...        -0.076126   \n","1816909464   0.635076  0.638642  0.517559  0.640020  ...        -0.067898   \n","...               ...       ...       ...       ...  ...              ...   \n","1816909464   0.632517  0.635378  0.513617  0.636183  ...        -0.122287   \n","1816909464   0.630854  0.633829  0.509058  0.634773  ...        -0.109587   \n","1816909464   0.629180  0.633134  0.514120  0.634424  ...        -0.109091   \n","1816909464   0.627741  0.632485  0.515145  0.634392  ...              NaN   \n","1816909464   0.633080  0.636270  0.517585  0.637478  ...        -0.303853   \n","\n","             z_right_hand_12  z_right_hand_13  z_right_hand_14  \\\n","sequence_id                                                      \n","1816909464         -0.104189        -0.045380        -0.121249   \n","1816909464         -0.109364        -0.056801        -0.140697   \n","1816909464         -0.072454        -0.027698        -0.106715   \n","1816909464         -0.063487        -0.018184        -0.096857   \n","1816909464         -0.054690        -0.014667        -0.092876   \n","...                      ...              ...              ...   \n","1816909464         -0.143393        -0.036747        -0.117303   \n","1816909464         -0.119431        -0.050337        -0.143903   \n","1816909464         -0.129037        -0.026356        -0.115820   \n","1816909464               NaN              NaN              NaN   \n","1816909464         -0.331745        -0.171783        -0.278637   \n","\n","             z_right_hand_15  z_right_hand_16  z_right_hand_17  \\\n","sequence_id                                                      \n","1816909464         -0.109559        -0.081881        -0.061576   \n","1816909464         -0.121780        -0.086510        -0.075543   \n","1816909464         -0.091961        -0.057869        -0.046882   \n","1816909464         -0.084778        -0.051440        -0.038928   \n","1816909464         -0.079966        -0.045867        -0.037966   \n","...                      ...              ...              ...   \n","1816909464         -0.145454        -0.143380        -0.059721   \n","1816909464         -0.168424        -0.159360        -0.061206   \n","1816909464         -0.146001        -0.140634        -0.049937   \n","1816909464               NaN              NaN              NaN   \n","1816909464         -0.297315        -0.286782        -0.194288   \n","\n","             z_right_hand_18  z_right_hand_19  z_right_hand_20  \n","sequence_id                                                     \n","1816909464         -0.120730        -0.112934        -0.093270  \n","1816909464         -0.137953        -0.123546        -0.098119  \n","1816909464         -0.102638        -0.088626        -0.063383  \n","1816909464         -0.095434        -0.083272        -0.058412  \n","1816909464         -0.093638        -0.080457        -0.054771  \n","...                      ...              ...              ...  \n","1816909464         -0.126471        -0.144004        -0.143947  \n","1816909464         -0.156683        -0.178238        -0.173135  \n","1816909464         -0.124411        -0.143374        -0.141726  \n","1816909464               NaN              NaN              NaN  \n","1816909464         -0.273722        -0.278472        -0.266041  \n","\n","[236 rows x 1630 columns]\n","Phrase name:  1383 william lanier\n"]}],"source":["sequence_id_3, file_id_3, phrase_3 = dataset_df.iloc[2][['sequence_id', 'file_id', 'phrase']]\n","sample_sequence_df_3 = pq.read_table(f\"/kaggle/input/asl-fingerspelling/train_landmarks/{str(file_id_3)}.parquet\",\n","                                  filters=[[('sequence_id', '=', sequence_id_3)], ]).to_pandas() # filter only applied to\n","print(\"The full sequence data frame is:\", sample_sequence_df_3, end=\"\\n\")\n","print(\"Phrase name: \", phrase_3)\n","\n","# Get the images created using mediapipe apis\n","hand_images_3, hand_landmarks_3 = get_hands(sample_sequence_df_3)\n","# Fetch and show the data for right hand\n","anim_2 = create_animation(np.array(hand_images_3)[:, 0])"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:44.340475Z","iopub.status.busy":"2023-07-22T15:02:44.339608Z","iopub.status.idle":"2023-07-22T15:02:57.001608Z","shell.execute_reply":"2023-07-22T15:02:57.000625Z","shell.execute_reply.started":"2023-07-22T15:02:44.340441Z"},"trusted":true},"outputs":[],"source":["anim_2.save('1383 william lanier.mp4', writer=writervideo)"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess the data\n","\n","Per [f'this notebook']({https://www.kaggle.com/code/gusthema/asl-fingerspelling-recognition-w-tensorflow#Fetch-the-pose-landmark-coordinates-related-to-hand-movement.}), we should arrange the data so that each parquet file not only contains the landmark coordinates but also the phrase it represents.\n","\n","The new data should be saved as TFRecord format.\n","The sample notebook focusses on hand movement and pose coordinates.\n","\n","# Fetch the pose landmark coordinates related to hand movement"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:57.003056Z","iopub.status.busy":"2023-07-22T15:02:57.002780Z","iopub.status.idle":"2023-07-22T15:02:57.008617Z","shell.execute_reply":"2023-07-22T15:02:57.007678Z","shell.execute_reply.started":"2023-07-22T15:02:57.003033Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[13, 15, 17, 19, 21, 14, 16, 18, 20, 22]\n"]}],"source":["# pose coordinates for hand movement.\n","LPOSE = [13, 15, 17, 19, 21]\n","RPOSE = [14, 16, 18, 20, 22]\n","\n","POSE = LPOSE + RPOSE # print [13, 15, 17, 19, 21, 14, 16, 18, 20, 22], essentially this combines the elements of LPOSE and RPOSE\n","# Note: there are 32 pose columns for each axis. However, only the 10 pose indexes above are related to hand, arm, and shouder.\n","print(POSE)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:57.010516Z","iopub.status.busy":"2023-07-22T15:02:57.010097Z","iopub.status.idle":"2023-07-22T15:02:57.037963Z","shell.execute_reply":"2023-07-22T15:02:57.037014Z","shell.execute_reply.started":"2023-07-22T15:02:57.010480Z"},"trusted":true},"outputs":[],"source":["# Create x, y, z label names from coordinates\n","\n","X = [f\"x_right_hand_{i}\" for i in range(21)] + [f\"x_left_hand_{i}\" for i in range(21)] + [f\"x_pose_{i}\" for i in POSE]\n","Y = [f\"y_right_hand_{i}\" for i in range(21)] + [f\"y_left_hand_{i}\" for i in range(21)] + [f\"y_pose_{i}\" for i in POSE]\n","Z = [f\"z_right_hand_{i}\" for i in range(21)] + [f\"z_left_hand_{i}\" for i in range(21)] + [f\"z_pose_{i}\" for i in POSE]\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:57.039730Z","iopub.status.busy":"2023-07-22T15:02:57.039415Z","iopub.status.idle":"2023-07-22T15:02:57.053347Z","shell.execute_reply":"2023-07-22T15:02:57.052276Z","shell.execute_reply.started":"2023-07-22T15:02:57.039699Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['x_right_hand_0', 'x_right_hand_1', 'x_right_hand_2', 'x_right_hand_3', 'x_right_hand_4', 'x_right_hand_5', 'x_right_hand_6', 'x_right_hand_7', 'x_right_hand_8', 'x_right_hand_9', 'x_right_hand_10', 'x_right_hand_11', 'x_right_hand_12', 'x_right_hand_13', 'x_right_hand_14', 'x_right_hand_15', 'x_right_hand_16', 'x_right_hand_17', 'x_right_hand_18', 'x_right_hand_19', 'x_right_hand_20', 'x_left_hand_0', 'x_left_hand_1', 'x_left_hand_2', 'x_left_hand_3', 'x_left_hand_4', 'x_left_hand_5', 'x_left_hand_6', 'x_left_hand_7', 'x_left_hand_8', 'x_left_hand_9', 'x_left_hand_10', 'x_left_hand_11', 'x_left_hand_12', 'x_left_hand_13', 'x_left_hand_14', 'x_left_hand_15', 'x_left_hand_16', 'x_left_hand_17', 'x_left_hand_18', 'x_left_hand_19', 'x_left_hand_20', 'x_pose_13', 'x_pose_15', 'x_pose_17', 'x_pose_19', 'x_pose_21', 'x_pose_14', 'x_pose_16', 'x_pose_18', 'x_pose_20', 'x_pose_22', 'y_right_hand_0', 'y_right_hand_1', 'y_right_hand_2', 'y_right_hand_3', 'y_right_hand_4', 'y_right_hand_5', 'y_right_hand_6', 'y_right_hand_7', 'y_right_hand_8', 'y_right_hand_9', 'y_right_hand_10', 'y_right_hand_11', 'y_right_hand_12', 'y_right_hand_13', 'y_right_hand_14', 'y_right_hand_15', 'y_right_hand_16', 'y_right_hand_17', 'y_right_hand_18', 'y_right_hand_19', 'y_right_hand_20', 'y_left_hand_0', 'y_left_hand_1', 'y_left_hand_2', 'y_left_hand_3', 'y_left_hand_4', 'y_left_hand_5', 'y_left_hand_6', 'y_left_hand_7', 'y_left_hand_8', 'y_left_hand_9', 'y_left_hand_10', 'y_left_hand_11', 'y_left_hand_12', 'y_left_hand_13', 'y_left_hand_14', 'y_left_hand_15', 'y_left_hand_16', 'y_left_hand_17', 'y_left_hand_18', 'y_left_hand_19', 'y_left_hand_20', 'y_pose_13', 'y_pose_15', 'y_pose_17', 'y_pose_19', 'y_pose_21', 'y_pose_14', 'y_pose_16', 'y_pose_18', 'y_pose_20', 'y_pose_22', 'z_right_hand_0', 'z_right_hand_1', 'z_right_hand_2', 'z_right_hand_3', 'z_right_hand_4', 'z_right_hand_5', 'z_right_hand_6', 'z_right_hand_7', 'z_right_hand_8', 'z_right_hand_9', 'z_right_hand_10', 'z_right_hand_11', 'z_right_hand_12', 'z_right_hand_13', 'z_right_hand_14', 'z_right_hand_15', 'z_right_hand_16', 'z_right_hand_17', 'z_right_hand_18', 'z_right_hand_19', 'z_right_hand_20', 'z_left_hand_0', 'z_left_hand_1', 'z_left_hand_2', 'z_left_hand_3', 'z_left_hand_4', 'z_left_hand_5', 'z_left_hand_6', 'z_left_hand_7', 'z_left_hand_8', 'z_left_hand_9', 'z_left_hand_10', 'z_left_hand_11', 'z_left_hand_12', 'z_left_hand_13', 'z_left_hand_14', 'z_left_hand_15', 'z_left_hand_16', 'z_left_hand_17', 'z_left_hand_18', 'z_left_hand_19', 'z_left_hand_20', 'z_pose_13', 'z_pose_15', 'z_pose_17', 'z_pose_19', 'z_pose_21', 'z_pose_14', 'z_pose_16', 'z_pose_18', 'z_pose_20', 'z_pose_22']\n"]}],"source":["# create the list of all feature columns created from the X, Y, Z above\n","FEATURE_COLUMNS = X + Y + Z\n","print(FEATURE_COLUMNS)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:57.057119Z","iopub.status.busy":"2023-07-22T15:02:57.056799Z","iopub.status.idle":"2023-07-22T15:02:57.066013Z","shell.execute_reply":"2023-07-22T15:02:57.065055Z","shell.execute_reply.started":"2023-07-22T15:02:57.057092Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[42, 43, 44, 45, 46, 94, 95, 96, 97, 98, 146, 147, 148, 149, 150]\n","_0\n","[13, 15, 17, 19, 21]\n"]}],"source":["# extract column ids based on the type of axis, i.e. x, y, or z\n","X_IDX = [i for i, col in enumerate(FEATURE_COLUMNS) if \"x_\" in col]\n","Y_IDX = [i for i, col in enumerate(FEATURE_COLUMNS) if \"y_\" in col]\n","Z_IDX = [i for i, col in enumerate(FEATURE_COLUMNS) if \"z_\" in col]\n","\n","# extract column ids based on the \n","RHAND_IDX = [i for i, col in enumerate(FEATURE_COLUMNS) if \"right\" in col]\n","LHAND_IDX = [i for i, col in enumerate(FEATURE_COLUMNS) if \"left\" in col]\n","RPOSE_IDX = [i for i, col in enumerate(FEATURE_COLUMNS) if \"pose\" in col and int(col[-2:]) in RPOSE]\n","LPOSE_IDX = [i for i, col in enumerate(FEATURE_COLUMNS) if \"pose\" in col and int(col[-2:]) in LPOSE] # the index of the pose must be in [14, 16, 18, 20, 22] to be considered a pose related to left_hand.\n","\n","print(LPOSE_IDX)\n","\n","print(FEATURE_COLUMNS[0][-2:])\n","print(LPOSE)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess and write the dataset as TFRecord\n","\n","# Using the extracted landmarks and phrases \n","\n","Note: Since this data set has 67208 parquet files. To work on development and to speed up prototype, we will be dealing with the first 1000 parquet files."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:57.067314Z","iopub.status.busy":"2023-07-22T15:02:57.067004Z","iopub.status.idle":"2023-07-22T15:02:57.079417Z","shell.execute_reply":"2023-07-22T15:02:57.078722Z","shell.execute_reply.started":"2023-07-22T15:02:57.067289Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[   5414471  105143404  128822441  149822653  152029243  169560558\n","  175396851  234418913  296317215  349393104  388576474  425182931\n","  433948159  450474571  474255203  495378749  522550314  527708222\n","  532011803  546816846  566963657  568753759  614661748  638508439\n","  649779897  654436541  683666742  871280215  882979387  933868835\n","  939623093 1019715464 1021040628 1098899348 1099408314 1133664520\n"," 1134756332 1255240050 1320204318 1341528257 1358493307 1365275733\n"," 1365772051 1405046009 1448136004 1497621680 1552432300 1557244878\n"," 1562234637 1643479812 1647220008 1662742697 1664666588 1726141437\n"," 1785039512 1865557033 1880177496 1905462118 1906357076 1920330615\n"," 1967755728 1969985709 1997878546 2026717426 2036580525 2072296290\n"," 2072876091 2118949241]\n"]}],"source":["print(dataset_df.file_id.unique())"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:02:57.080865Z","iopub.status.busy":"2023-07-22T15:02:57.080578Z","iopub.status.idle":"2023-07-22T15:11:56.385022Z","shell.execute_reply":"2023-07-22T15:11:56.383065Z","shell.execute_reply.started":"2023-07-22T15:02:57.080840Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58e9c0e37fd34e99988792ee9eebde37","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/68 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Set length of frames to 128\n","\n","FRAME_LEN = 128\n","\n","# create directory to store the new data if not exist yet. If the \"preprocessed\" folder already exists, create a new one with the same name.\n","if not os.path.isdir(\"preprocessed\"):\n","    os.mkdir(\"preprocessed\")\n","else:\n","    shutil.rmtree(\"preprocessed\")\n","    os.mkdir(\"preprocessed\")\n","\n","# loop through each file_id. Note the tqdm wrapper helps show progress\n","for file_id in tqdm(dataset_df.file_id.unique()):\n","    # parquet file name\n","    pq_file = f\"/kaggle/input/asl-fingerspelling/train_landmarks/{file_id}.parquet\"\n","    # Filter train.csv and fetch entries only for the relevant file_id\n","    file_df = dataset_df.loc[dataset_df['file_id'] == file_id]\n","    \n","    # fetch the parquet file\n","    parquet_df = pq.read_table(f\"/kaggle/input/asl-fingerspelling/train_landmarks/{str(file_id)}.parquet\",\n","                              columns=['sequence_id'] + FEATURE_COLUMNS).to_pandas()\n","    \n","    # File name for the updated data\n","    tf_file = f\"preprocessed/{file_id}.tfrecord\"\n","    parquet_numpy = parquet_df.to_numpy()\n","    \n","    # Initialize the pointer to write the output of each `for loop` below as a sequence into the file.\n","    with tf.io.TFRecordWriter(tf_file) as file_writer:\n","        # Loop through each sequence in file.\n","        for seq_id, phrase in zip(file_df.sequence_id, file_df.phrase):\n","            # fetch sequence data\n","            frames = parquet_numpy[parquet_df.index == seq_id]\n","            \n","            # Calculate the number of NaN values in each hand landmark\n","            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_IDX]), axis = 1) == 0)\n","            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_IDX]), axis = 1) == 0)\n","            \n","            no_nan = max(r_nonan, l_nonan)\n","            \n","            if 2*len(phrase) < no_nan:\n","                features = {FEATURE_COLUMNS[i]: tf.train.Feature(\n","                    float_list = tf.train.FloatList(value=frames[:, i])) for i in range(len(FEATURE_COLUMNS))}\n","                features[\"phrase\"] = tf.train.Feature(bytes_list = tf.train.BytesList(value = [bytes(phrase, 'utf-8')]))\n","                record_bytes = tf.train.Example(features = tf.train.Features(feature = features)).SerializeToString()\n","                file_writer.write(record_bytes)\n","            \n","            "]},{"cell_type":"markdown","metadata":{},"source":["# Load character_to_prediction json file\n","\n","The json file contains a character and its value. We will add 3 new characters, \"<\" and \">\" to mark the start and end of a phrase and \"P\" for padding.\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:11:56.388437Z","iopub.status.busy":"2023-07-22T15:11:56.387795Z","iopub.status.idle":"2023-07-22T15:11:56.406260Z","shell.execute_reply":"2023-07-22T15:11:56.404765Z","shell.execute_reply.started":"2023-07-22T15:11:56.388389Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: ' ', 1: '!', 2: '#', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: '+', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '=', 28: '?', 29: '@', 30: '[', 31: '_', 32: 'a', 33: 'b', 34: 'c', 35: 'd', 36: 'e', 37: 'f', 38: 'g', 39: 'h', 40: 'i', 41: 'j', 42: 'k', 43: 'l', 44: 'm', 45: 'n', 46: 'o', 47: 'p', 48: 'q', 49: 'r', 50: 's', 51: 't', 52: 'u', 53: 'v', 54: 'w', 55: 'x', 56: 'y', 57: 'z', 58: '~', 59: 'P', 60: '<', 61: '>'}\n"]}],"source":["with open(\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n","    char_to_num = json.load(f)\n","\n","# char_to_num is now a dictionary that map a character to the numeric label value. Since there are no tokens to represent pad_token, start_pointer and end_pointer, we will add to the dict.\n","# define those extra tokens:\n","pad_token = 'P'\n","start_token = '<'\n","end_token = '>'\n","pad_token_idx = 59 # the next integer value that hasn't been assigned to any characters.\n","start_token_idx = 60\n","end_token_idx = 61\n","\n","char_to_num[pad_token] = pad_token_idx\n","char_to_num[start_token] = start_token_idx\n","char_to_num[end_token] = end_token_idx\n","\n","\n","num_to_char = {j : i for i, j in char_to_num.items()} # swap the keys to the values in the dictionary, why do we need to swap?\n","print(num_to_char)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:11:56.408361Z","iopub.status.busy":"2023-07-22T15:11:56.407811Z","iopub.status.idle":"2023-07-22T15:11:56.431153Z","shell.execute_reply":"2023-07-22T15:11:56.429802Z","shell.execute_reply.started":"2023-07-22T15:11:56.408316Z"},"trusted":true},"outputs":[],"source":["def resize_pad(x):\n","    \"\"\"\n","    this function resizes and adds padding to the input tensor x. The function first checks if the number of rows in x is less than FRAME_LEN (i.e. 128 as defined earlier). If so, it pads the tensor with zeros so that it has FRAME_LEN rows.\n","    If not, it resizes the tensor to have FRAME_LEN rows using bilinear interpolation. The function then returns the resized and padded tensor.\n","    \"\"\"\n","    if tf.shape(x)[0] < FRAME_LEN:\n","        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]))\n","    else:\n","        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n","    return x\n","\n","def pre_process(x):\n","    \"\"\"\n","    This function does:\n","    - Detect the dominant hand from the number of NaN values. Dominant hand will have less NaN values since it is in frame moving.\n","    \"\"\"\n","    rhand = tf.gather(x, RHAND_IDX, axis=1)\n","    lhand = tf.gather(x, LHAND_IDX, axis=1)\n","    rpose = tf.gather(x, RPOSE_IDX, axis=1)\n","    lpose = tf.gather(x, LPOSE_IDX, axis=1)\n","    \n","    \n","    rnan_idx = tf.reduce_any(tf.math.is_nan(rhand), axis=1)\n","    lnan_idx = tf.reduce_any(tf.math.is_nan(lhand), axis=1)\n","    \n","    rnans = tf.math.count_nonzero(rnan_idx)\n","    lnans = tf.math.count_nonzero(lnan_idx)\n","    \n","    # for dominant hand\n","    if rnans > lnans:\n","        hand = lhand\n","        pose = lpose\n","        \n","        hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)] # this extracts the x-coordinates from the tensor hand, len(LHAND_IDX)\n","        hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n","        hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3 )]\n","        \n","        ## concatenate all the axes but also flips the x-coordinates of the left hand and pose. Since the left hand is mirrored in the input image, so its x-coordinates are flipped relative to the right hand.\n","        hand = tf.concat([1-hand_x, hand_y, hand_z], axis=1)\n","        \n","        # repeat the same for the left pose:\n","        pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n","        pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n","        pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n","        pose = tf.concat([1-pose_x, pose_y, pose_z], axis=1)\n","        \n","    else:\n","        hand = rhand\n","        pose = rpose\n","        \n","    # This blocks of code extracts the x-coordinate, y-coordinate, z-coordinate of the hand from the tensor`hand`, concatenates them into a single tensor using tf.concat(), and add a new axis to each\n","    # coordinate using [..., tf.newaxis] so they can be concatenated into a 3D tensor.\n","    #\n","    \n","    hand_x = hand[:, 0*(len(LHAND_IDX)//3) : 1*(len(LHAND_IDX)//3)]\n","    hand_y = hand[:, 1*(len(LHAND_IDX)//3) : 2*(len(LHAND_IDX)//3)]\n","    hand_z = hand[:, 2*(len(LHAND_IDX)//3) : 3*(len(LHAND_IDX)//3)]\n","    hand = tf.concat([hand_x[..., tf.newaxis], hand_y[..., tf.newaxis], hand_z[..., tf.newaxis]], axis=-1) # note: the `...` syntax is used to select all dimensions of the tensor except for the last one\n","    \n","    \n","    # normalize the coordinate values of hands\n","    mean = tf.math.reduce_mean(hand, axis=1)[:, tf.newaxis, :]\n","    std = tf.math.reduce_std(hand, axis=1)[:, tf.newaxis, :]\n","    hand = (hand - mean)/std\n","    \n","    # add a new axis to \"pose\" similarly to the \"hand\" above\n","    pose_x = pose[:, 0*(len(LPOSE_IDX)//3) : 1*(len(LPOSE_IDX)//3)]\n","    pose_y = pose[:, 1*(len(LPOSE_IDX)//3) : 2*(len(LPOSE_IDX)//3)]\n","    pose_z = pose[:, 2*(len(LPOSE_IDX)//3) : 3*(len(LPOSE_IDX)//3)]\n","    pose = tf.concat([pose_x[..., tf.newaxis], pose_y[..., tf.newaxis], pose_z[..., tf.newaxis]], axis=-1) # meaning the function will gather values along the last dimension of the tensor.\n","    \n","    x = tf.concat([hand, pose], axis=1)\n","    x = resize_pad(x)\n","    \n","    x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x) # replace all the NaN values in tensor x with zeros\n","    x = tf.reshape(x, (FRAME_LEN, len(LHAND_IDX) + len(LPOSE_IDX))) # reshape the tensor x into a new shape. note that the second dimension has a length of len(LHAND_IDX) + len(LPOSE_IDX) since all right hands features are no longer considered(due to having a lot of NaN values.)\n","    return x"]},{"cell_type":"markdown","metadata":{},"source":["# Create function to parse data from TFRecord format"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:11:56.433025Z","iopub.status.busy":"2023-07-22T15:11:56.432682Z","iopub.status.idle":"2023-07-22T15:11:56.448689Z","shell.execute_reply":"2023-07-22T15:11:56.447706Z","shell.execute_reply.started":"2023-07-22T15:11:56.432997Z"},"trusted":true},"outputs":[],"source":["def decode_fn(record_bytes):\n","    \"\"\"\n","    this is to decode a single .tfrecord file. A schema is used to map feature names to their corresponding data types.\n","    the \"phrase\" feature in the schema data type is a tf.string data type.\n","    \n","    @param record_bytes: a binary string representation of the .tfrecord file.\n","    @return landmarks\n","    \"\"\"\n","    schema = {COL : tf.io.VarLenFeature(dtype=tf.float32) for COL in FEATURE_COLUMNS} # dictionary comprehension?\n","    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n","    features = tf.io.parse_single_example(record_bytes, schema)\n","    phrase = features[\"phrase\"]\n","    landmarks = ([tf.sparse.to_dense(features[COL]) for COL in FEATURE_COLUMNS]) # landmarks is a rank 2 tensor\n","    \n","    # Transpose to maintain the original shape of landmarks data\n","    landmarks = tf.transpose(landmarks)\n","    \n","    return landmarks, phrase"]},{"cell_type":"markdown","metadata":{},"source":["# Create function to convert the data"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:11:56.451007Z","iopub.status.busy":"2023-07-22T15:11:56.450577Z","iopub.status.idle":"2023-07-22T15:11:56.647321Z","shell.execute_reply":"2023-07-22T15:11:56.646141Z","shell.execute_reply.started":"2023-07-22T15:11:56.450968Z"},"trusted":true},"outputs":[],"source":["# transposes and applies masks to the landmark coordinates. It also vectorized the phrase corresponding to the landmarks using `character_to_prediction_index.json`\n","\n","# Note: Static\n","\n","table = tf.lookup.StaticHashTable(\n","        initializer = tf.lookup.KeyValueTensorInitializer(\n","            keys = list(char_to_num.keys()),\n","            values = list(char_to_num.values()),\n","        ),\n","        default_value = tf.constant(-1), # to be returned when the key is not found in the table\n","        name = \"class_weight\" # an arbitrary name given to the table.\n","        )\n","\n","def convert_fn(landmarks, phrase): \n","    \"\"\"\n","    preprocess the landmark also alter the phrase associated with the collection of landmarks\n","    by adding start_token, end_token, and padding.\n","    \n","    \"\"\"\n","    # add the start and end pointers to a phrase, e.g. \"<\" for start pointer, and \">\" for end pointer\n","    phrase = start_token + phrase + end_token\n","    phrase = tf.strings.bytes_split(phrase)  # split string into bytes, not unicode characters since in the `decode_fn()` earlier we defined phrase as of type tf.string\n","    phrase = table.lookup(phrase)\n","    \n","    # Vectorize and add padding\n","    phrase = tf.pad(phrase, \n","                    paddings=[[0, 64 - tf.shape(phrase)[0]]], \n","                    mode = 'CONSTANT',\n","                    constant_values = pad_token_idx)\n","    \n","    phrase = tf.one_hot(phrase, depth=len(num_to_char), axis=-1)\n","    \n","    # apply pre-process function to the landmarks\n","    return pre_process(landmarks), phrase\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Train and validation split/ Create the final datasets"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:11:56.654705Z","iopub.status.busy":"2023-07-22T15:11:56.654306Z","iopub.status.idle":"2023-07-22T15:11:59.188233Z","shell.execute_reply":"2023-07-22T15:11:59.186868Z","shell.execute_reply.started":"2023-07-22T15:11:56.654676Z"},"trusted":true},"outputs":[],"source":["# we can't load the whole data set into memory at once so we will train and fetch by a batch of size 64.\n","# splitting the data set into train, validation and test set\n","\n","batch_size = 64\n","train_len = int(0.7 * len(tf_records))\n","valid_len = int(0.15 * len(tf_records))\n","test_len = int(0.15 * len(tf_records))\n","\n","train_ds = tf.data.TFRecordDataset(tf_records[:train_len]).map(decode_fn).map(convert_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n","valid_ds = tf.data.TFRecordDataset(tf_records[train_len:train_len+valid_len]).map(decode_fn).map(convert_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n","test_ds = tf.data.TFRecordDataset(tf_records[train_len+valid_len:]).map(decode_fn).map(convert_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n","\n","\n","# Note: train_ds is of type <CacheDataset element_spec=(TensorSpec(shape=(None, 128, 78), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int32, name=None))>\n","# valid_ds is of type <CacheDataset element_spec=(TensorSpec(shape=(None, 128, 78), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int32, name=None))>"]},{"cell_type":"markdown","metadata":{},"source":["# Start of the LSTM model"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:11:59.190470Z","iopub.status.busy":"2023-07-22T15:11:59.190009Z","iopub.status.idle":"2023-07-22T15:12:10.704522Z","shell.execute_reply":"2023-07-22T15:12:10.703069Z","shell.execute_reply.started":"2023-07-22T15:11:59.190433Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-Levenshtein in /opt/conda/lib/python3.10/site-packages (0.21.1)\n","Requirement already satisfied: Levenshtein==0.21.1 in /opt/conda/lib/python3.10/site-packages (from python-Levenshtein) (0.21.1)\n","Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install python-Levenshtein"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:12:10.706632Z","iopub.status.busy":"2023-07-22T15:12:10.706247Z","iopub.status.idle":"2023-07-22T15:12:10.827032Z","shell.execute_reply":"2023-07-22T15:12:10.825678Z","shell.execute_reply.started":"2023-07-22T15:12:10.706587Z"},"trusted":true},"outputs":[],"source":["import Levenshtein"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-07-21T23:30:24.993843Z","iopub.status.busy":"2023-07-21T23:30:24.993383Z","iopub.status.idle":"2023-07-21T23:30:25.001316Z","shell.execute_reply":"2023-07-21T23:30:25.000252Z","shell.execute_reply.started":"2023-07-21T23:30:24.993811Z"}},"source":["# TODO: fix the bug since there seems to be a mismatch in shapes.\n","\n","from keras import backend\n","\n","def levenshtein_metric(y_true, y_pred):\n","    \"\"\"\n","    calculate the Levenshtein distance between y_true and y_pred\n","    assuming y_true is a rank 2 tensor of shape shape=(64, 64), dtype=int32\n","    \n","    to use it: in the metrics argument of model.compile, set metrics=[levenshtein_metric]\n","    \"\"\"\n","    y_true = decode_prediction(y_true) #return tensor of strings\n","    y_pred = decode_prediction(y_pred)\n","    lev_dist = Levenshtein.distance(y_true, y_pred)\n","    return backend.mean(backend.square(lev_dist), axis=None)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:12:10.828801Z","iopub.status.busy":"2023-07-22T15:12:10.828471Z","iopub.status.idle":"2023-07-22T15:12:12.298977Z","shell.execute_reply":"2023-07-22T15:12:12.296026Z","shell.execute_reply.started":"2023-07-22T15:12:10.828773Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 75)                46200     \n","                                                                 \n"," repeat_vector (RepeatVector  (None, 128, 75)          0         \n"," )                                                               \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128, 50)           25200     \n","                                                                 \n"," time_distributed (TimeDistr  (None, 128, 62)          3162      \n"," ibuted)                                                         \n","                                                                 \n"," lambda (Lambda)             (None, 64, 62)            0         \n","                                                                 \n","=================================================================\n","Total params: 74,562\n","Trainable params: 74,562\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["num_classes = len(char_to_num)\n","batch_size, frame_len, num_features = next(iter(valid_ds))[0].shape\n","\n","#define LSTM\n","model = keras.Sequential()\n","model.add(layers.LSTM(75, input_shape=(frame_len, num_features)))\n","model.add(layers.RepeatVector(FRAME_LEN))\n","#.5. Fit the Model 122\n","model.add(layers.LSTM(50, return_sequences=True))\n","model.add(layers.TimeDistributed(layers.Dense(num_classes, activation= 'softmax')))\n","model.add(layers.Lambda(lambda x: x[:, ::2, :]))  # Perform downsampling, halving the sequence length\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer= 'adam' , metrics=[ 'accuracy' ]) # TODO: find a way to get Levenshtein currently we are just using a generic \"accuracy\" metric\n","# but we really need to use levenshtein metric - this is a custom metric so you probably need to define it some way\n","print(model.summary())"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-07-22T15:26:17.010773Z","iopub.status.busy":"2023-07-22T15:26:17.010250Z","iopub.status.idle":"2023-07-22T15:26:17.018067Z","shell.execute_reply":"2023-07-22T15:26:17.016837Z","shell.execute_reply.started":"2023-07-22T15:26:17.010736Z"},"trusted":true},"outputs":[],"source":["def decode_prediction(y_pred):\n","    \"\"\"\n","    function to decode the prediction, assumming shape of (None, 64, 62); next we can try with shape (1, 64, 62)\n","    \n","    this function will be used in the DisplayOutputs callback\n","    \"\"\"\n","    # reverse decode the one-hot labels of y\n","    y_pred = tf.argmax(y_pred, axis=2)\n","    \n","    labels = []\n","    \n","    for i in y_pred:\n","        decoded = ''\n","        for integer_tensor in i:\n","            squeezed_integer = tf.squeeze(integer_tensor)\n","            integer_val = int(squeezed_integer.numpy())\n","            decoded += num_to_char[integer_val]\n","        labels.append(decoded)\n","#     labels = tf.convert_to_tensor(labels)\n","    return labels\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-22T15:12:13.643256Z","iopub.status.idle":"2023-07-22T15:12:13.644453Z","shell.execute_reply":"2023-07-22T15:12:13.644144Z","shell.execute_reply.started":"2023-07-22T15:12:13.644114Z"},"trusted":true},"outputs":[],"source":["class DisplayOutputs(keras.callbacks.Callback):\n","    def __init__(\n","        self, batch\n","    ):\n","        \"\"\"Displays a batch of outputs after every 4 epoch\n","\n","        Args:\n","            batch: A test batch\n","        \"\"\"\n","        self.batch = batch\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch % 4 != 0: # this only prints out the prediction for every 4 epochs just to save the computational bandwidth\n","            return\n","        source = self.batch[0]\n","        target = self.batch[1]\n","        batch_size = tf.shape(source)[0]\n","        preds = self.model(source)\n","        \n","        target_labels = decode_prediction(target)\n","        predicted_labels = decode_prediction(preds)\n","        \n","        for target_label, predicted_label in zip(target_labels, predicted_labels):\n","            print(f\"Target Label: {target_label}\\t Predicted Label: {predicted_label}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-22T15:12:13.646180Z","iopub.status.idle":"2023-07-22T15:12:13.646614Z","shell.execute_reply":"2023-07-22T15:12:13.646444Z","shell.execute_reply.started":"2023-07-22T15:12:13.646426Z"},"trusted":true},"outputs":[],"source":["# DisplayOutputs callback\n","batch = next(iter(test_ds))\n","display_cb = DisplayOutputs(batch)\n","\n","num_epochs = 4\n","\n","\n","# fitting the model by passing in the train_ds, valid_ds\n","\n","# Note: Please change the number of epochs to 20. I put 4 here just for the prototype; Warning: training may take a lot of time\n","history = model.fit(train_ds, epochs=num_epochs, validation_data=valid_ds, callbacks=[display_cb])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-22T15:12:13.648893Z","iopub.status.idle":"2023-07-22T15:12:13.649492Z","shell.execute_reply":"2023-07-22T15:12:13.649242Z","shell.execute_reply.started":"2023-07-22T15:12:13.649196Z"},"trusted":true},"outputs":[],"source":["# to predict based on the first batch of the test_ds\n","\n","next_test_input = next(iter(test_ds))[0] # get the next batch of 64 records in the test_ds data set\n","y_preds = model.predict(next_test_input)\n","\n","# display the predicted labels\n","decode_prediction(y_preds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-22T15:12:13.651332Z","iopub.status.idle":"2023-07-22T15:12:13.651914Z","shell.execute_reply":"2023-07-22T15:12:13.651648Z","shell.execute_reply.started":"2023-07-22T15:12:13.651620Z"},"trusted":true},"outputs":[],"source":["# Access training and validation metrics\n","train_loss = history.history['loss']\n","train_accuracy = history.history['accuracy']\n","valid_loss = history.history['val_loss']\n","valid_accuracy = history.history['val_accuracy']\n","\n","\n","# Example: Print the training and validation loss for each epoch\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}:\\n Training Loss={train_loss[epoch]} \\n Validation Loss={valid_loss[epoch]} \\n Training accuracy={train_accuracy[epoch]} \\n Validation Accuracy={valid_accuracy[epoch]}\\n\\n\")\n","    \n","    \n","# Example: Access the final training accuracy and validation accuracy\n","\n","final_train_accuracy = train_accuracy[-1]\n","final_valid_accuracy = valid_accuracy[-1]\n","print(f\"Final Training Accuracy: {final_train_accuracy}\")\n","print(f\"Final Validation Accuracy: {final_valid_accuracy}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
